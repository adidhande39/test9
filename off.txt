import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.DescribeTopicsResult;
import org.apache.kafka.clients.admin.TopicDescription;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.config.SaslConfigs;
import org.springframework.kafka.core.KafkaAdmin;
import org.springframework.stereotype.Service;

import java.util.Collections;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ExecutionException;

@Service
public class KafkaService {
    
    private final KafkaAdmin kafkaAdmin;

    public KafkaService(KafkaAdmin kafkaAdmin) {
        this.kafkaAdmin = kafkaAdmin;
    }

    public long getCurrentOffsetForPartition(String topic, int partition) throws ExecutionException, InterruptedException {
        AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfig());
        Map<TopicPartition, Long> offsets = adminClient.listConsumerGroupOffsets("<your_consumer_group>").partitionsToOffsetAndMetadata().get();
        TopicDescription topicDescription = adminClient.describeTopics(Collections.singletonList(topic)).all().get().get(topic);
        long endOffset = topicDescription.partitions().get(partition).partitionSize();
        long currentOffset = offsets.get(new TopicPartition(topic, partition)).offset();
        adminClient.close();
        return endOffset - currentOffset;
    }

}





import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

import java.util.concurrent.ExecutionException;

@Service
public class KafkaService {

    private final KafkaTemplate<String, String> kafkaTemplate;

    public KafkaService(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public long sendAndGetOffset(String topic, String key, String value) throws ExecutionException, InterruptedException {
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
        RecordMetadata metadata = kafkaTemplate.executeInTransaction(operations -> {
            try {
                return operations.send(record).get().getRecordMetadata();
            } catch (InterruptedException | ExecutionException e) {
                throw new RuntimeException(e);
            }
        });
        return metadata.offset();
    }
}


import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.springframework.stereotype.Service;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

@Service
public class KafkaService {

    private final Producer<String, String> producer;

    public KafkaService() {
        Properties properties = new Properties();
        properties.put("bootstrap.servers", "<your_bootstrap_servers>");
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        producer = new KafkaProducer<>(properties);
    }

    public long sendAndGetOffset(String topic, String key, String value) throws ExecutionException, InterruptedException {
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
        RecordMetadata metadata = producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    throw new RuntimeException(exception);
                }
            }
        }).get();
        return metadata.offset();
    }
}



import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CompletableFuture;

public class PostRequestSender {

    public static void sendPostRequests() {
        HttpClient client = HttpClient.newHttpClient();
        List<CompletableFuture<Void>> futures = new ArrayList<>();

        for (int i = 0; i < 50; i++) {
            String requestBody = "{\"index\": " + i + "}";

            HttpRequest request = HttpRequest.newBuilder()
                    .uri(URI.create("http://example.com/api"))
                    .header("Content-Type", "application/json")
                    .POST(HttpRequest.BodyPublishers.ofString(requestBody))
                    .build();

            CompletableFuture<Void> future = client.sendAsync(request, HttpResponse.BodyHandlers.discarding())
                    .thenApply(HttpResponse::statusCode)
                    .thenAccept(statusCode -> System.out.println("Status code: " + statusCode))
                    .exceptionally(ex -> {
                        System.out.println("Exception: " + ex.getMessage());
                        return null;
                    })
                    .thenApply(ignore -> null);

            futures.add(future);
        }

        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
    }
}
